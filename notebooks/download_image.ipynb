{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f7a1812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import albumentations as A\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea779616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data constants\n",
    "ROBOFLOW_API_KEY = \"6Zww8x98VFrvYjTYjNnN\"\n",
    "\n",
    "DATA_FOLDER = \"../data/\"\n",
    "\n",
    "DATASET_DETAILS = {\n",
    "    \"dataset_amount\": 2,\n",
    "    \"workspace_name\": [\"computer-vision-project-y5j59\", \"computer-vision-project-y5j59\"],\n",
    "    \"project_name\": [\"pomelo-yotwr-e5cxd\", \"pomelo-ripeness-detection-using-yolov7-network-fr6ma\"],\n",
    "    \"model_format\": [\"coco\", \"multiclass\"],\n",
    "    \"version\": [1, 1],\n",
    "    \"dataset_folder_name\": [\"pomelo-1\", \"Pomelo-Ripeness-Detection-using-YOLOv7-Network-1\"],\n",
    "}\n",
    "\n",
    "RIPE_COLUMN_GROUPS = [\"ripe\", \"old\", \"overripe\"]\n",
    "NOT_RIPE_COLUMN_GROUPS = [\"young\"]\n",
    "IGNORE_COLUMNS = [\"testset\", \"filename\", \"not-ripe\", \"ripe\"]\n",
    "\n",
    "TOTAL_PATH = os.path.join(DATA_FOLDER, \"total\")\n",
    "\n",
    "DETECTION_VAL_SIZE = 0.1\n",
    "DETECTION_TEST_SIZE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1191fe3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jirayuwat/Desktop/pomelo-detection-system/.venv/lib/python3.11/site-packages/albumentations/core/validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Augmentation constants\n",
    "CLASSIFICATION_AUGS = A.Compose([\n",
    "    A.VerticalFlip(p=0.5), # Flip the image vertically (no horizontal flip for real-world images)\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=60, interpolation=cv2.INTER_CUBIC, border_mode=cv2.BORDER_REPLICATE, p=0.5), # Shift, scale, and rotate the image\n",
    "    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=20, val_shift_limit=20, p=0.5), # Change the hue, saturation, and value of the image, in case that smartphone camera did filter the image\n",
    "    A.RandomBrightnessContrast(p=0.2), # Change the brightness and contrast of the image, for handling the lighting condition\n",
    "])\n",
    "DETECTION_AUGS = A.Compose([\n",
    "    A.BBoxSafeRandomCrop(p=0.5), # Randomly crop the image while keeping the bounding boxes safe\n",
    "    A.HorizontalFlip(p=0.5), # Flip the image horizontally\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=60, interpolation=cv2.INTER_CUBIC, border_mode=cv2.BORDER_REPLICATE, p=0.5), # Shift, scale, and rotate the image\n",
    "    A.GaussianBlur(blur_limit=(3, 7), p=0.5), # Add Gaussian blur, in case that user did not focus the camera well\n",
    "    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=20, val_shift_limit=20, p=0.5), # Change the hue, saturation, and value of the image, in case that smartphone camera did filter the image\n",
    "    A.RandomBrightnessContrast(p=0.2), # Change the brightness and contrast of the image, for handling the lighting condition\n",
    "], bbox_params=A.BboxParams(format='coco', label_fields=['category_ids'], min_visibility=0.8))\n",
    "\n",
    "AUGMENTATION_AMOUNT = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76e6b5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "rf = Roboflow(api_key=ROBOFLOW_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba058cb",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f576200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecbe2850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in pomelo-1 to coco:: 100%|██████████| 58108/58108 [00:04<00:00, 11731.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to pomelo-1 in coco:: 100%|██████████| 219/219 [00:00<00:00, 1662.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Pomelo-Ripeness-Detection-using-YOLOv7-Network-1 to multiclass:: 100%|██████████| 249939/249939 [00:16<00:00, 15319.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Pomelo-Ripeness-Detection-using-YOLOv7-Network-1 in multiclass:: 100%|██████████| 242/242 [00:00<00:00, 376.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Download the datasets\n",
    "for dataset_index in range(DATASET_DETAILS[\"dataset_amount\"]):\n",
    "    workspace_name = DATASET_DETAILS[\"workspace_name\"][dataset_index]\n",
    "    project_name = DATASET_DETAILS[\"project_name\"][dataset_index]\n",
    "    model_format = DATASET_DETAILS[\"model_format\"][dataset_index]\n",
    "    version_number = DATASET_DETAILS[\"version\"][dataset_index]\n",
    "    dataset_folder_name = DATASET_DETAILS[\"dataset_folder_name\"][dataset_index]\n",
    "\n",
    "    # Download the dataset\n",
    "    project = rf.workspace(workspace_name).project(project_name)\n",
    "    version = project.version(version_number)\n",
    "    dataset = version.download(model_format)\n",
    "\n",
    "    # Define the source and destination paths\n",
    "    source_path = dataset_folder_name\n",
    "    destination_path = os.path.join(DATA_FOLDER, dataset_folder_name)\n",
    "\n",
    "    # Create the destination directory if it doesn't exist\n",
    "    if not os.path.exists(destination_path):\n",
    "        os.makedirs(destination_path)\n",
    "\n",
    "    # Remove exists destination folder\n",
    "    shutil.rmtree(destination_path, ignore_errors=True)\n",
    "\n",
    "    # Move the dataset folder to the destination\n",
    "    shutil.move(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1c606d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename folder\n",
    "for dataset_index in range(DATASET_DETAILS[\"dataset_amount\"]):\n",
    "    dataset_folder_name = DATASET_DETAILS[\"dataset_folder_name\"][dataset_index]\n",
    "    new_dataset_folder_name = \"pomelo-\" + (\n",
    "        \"detection\" if DATASET_DETAILS[\"model_format\"][dataset_index] == \"coco\" else \"classification\"\n",
    "    )\n",
    "\n",
    "    new_dataset_folder_path = os.path.join(DATA_FOLDER, new_dataset_folder_name)\n",
    "    dataset_folder_path = os.path.join(DATA_FOLDER, dataset_folder_name)\n",
    "\n",
    "    # Remove exists new dataset folder\n",
    "    shutil.rmtree(new_dataset_folder_path, ignore_errors=True)\n",
    "    # Rename the dataset folder\n",
    "    shutil.move(dataset_folder_path, new_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9094ce83",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e744dc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2847e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_folder = os.path.join(DATA_FOLDER, \"pomelo-detection\")\n",
    "temp_folder = os.path.join(detection_folder, \"temp\")\n",
    "train_folder = os.path.join(detection_folder, \"train\")\n",
    "valid_folder = os.path.join(detection_folder, \"valid\")\n",
    "test_folder = os.path.join(detection_folder, \"test\")\n",
    "\n",
    "os.makedirs(temp_folder, exist_ok=True)\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(valid_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64932ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move all from train folder to temp folder\n",
    "if os.path.exists(temp_folder):\n",
    "    shutil.rmtree(temp_folder, ignore_errors=True)\n",
    "os.makedirs(temp_folder, exist_ok=True)\n",
    "for filename in os.listdir(train_folder):\n",
    "    file_path = os.path.join(train_folder, filename)\n",
    "    shutil.move(file_path, temp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c2aeee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_json = json.load(open(os.path.join(temp_folder, \"_annotations.coco.json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "032fda62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 215\n",
      "Train images: 173\n",
      "Valid images: 22\n",
      "Test images: 20\n"
     ]
    }
   ],
   "source": [
    "total_images_id = [image[\"id\"] for image in annotation_json[\"images\"]]\n",
    "train_images_id, valid_images_id = train_test_split(total_images_id, test_size=DETECTION_VAL_SIZE, random_state=42)\n",
    "train_images_id, test_images_id = train_test_split(train_images_id, test_size=DETECTION_TEST_SIZE, random_state=42)\n",
    "\n",
    "print(f\"Total images: {len(total_images_id)}\")\n",
    "print(f\"Train images: {len(train_images_id)}\")\n",
    "print(f\"Valid images: {len(valid_images_id)}\")\n",
    "print(f\"Test images: {len(test_images_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d09c661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_annotations = {\n",
    "    \"info\": annotation_json[\"info\"],\n",
    "    \"licenses\": annotation_json[\"licenses\"],\n",
    "    \"categories\": annotation_json[\"categories\"],\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "}\n",
    "train_annotations = copy.deepcopy(default_annotations)\n",
    "valid_annotations = copy.deepcopy(default_annotations)\n",
    "test_annotations = copy.deepcopy(default_annotations)\n",
    "\n",
    "target_folder_by_set = {\"train\": train_folder, \"valid\": valid_folder, \"test\": test_folder}\n",
    "\n",
    "for image in annotation_json[\"images\"]:\n",
    "    image_id = image[\"id\"]\n",
    "    file_is_in = None\n",
    "    if image_id in train_images_id:\n",
    "        file_is_in = \"train\"\n",
    "        train_annotations[\"images\"].append(image)\n",
    "    elif image_id in valid_images_id:\n",
    "        file_is_in = \"valid\"\n",
    "        valid_annotations[\"images\"].append(image)\n",
    "    elif image_id in test_images_id:\n",
    "        file_is_in = \"test\"\n",
    "        test_annotations[\"images\"].append(image)\n",
    "\n",
    "    # Add image to the corresponding set\n",
    "    source_image_path = os.path.join(temp_folder, image[\"file_name\"])\n",
    "    target_image_path = os.path.join(target_folder_by_set[file_is_in], image[\"file_name\"])\n",
    "    shutil.copy(source_image_path, target_image_path)\n",
    "\n",
    "for annotation in annotation_json[\"annotations\"]:\n",
    "    image_id = annotation[\"image_id\"]\n",
    "    if image_id in train_images_id:\n",
    "        train_annotations[\"annotations\"].append(annotation)\n",
    "    if image_id in valid_images_id:\n",
    "        valid_annotations[\"annotations\"].append(annotation)\n",
    "    if image_id in test_images_id:\n",
    "        test_annotations[\"annotations\"].append(annotation)\n",
    "\n",
    "# Save the new annotations\n",
    "for set_name, annotations in zip([\"train\", \"valid\", \"test\"], [train_annotations, valid_annotations, test_annotations]):\n",
    "    with open(os.path.join(target_folder_by_set[set_name], \"_annotations.coco.json\"), \"w\") as f:\n",
    "        json.dump(annotations, f)\n",
    "\n",
    "# Remove temp folder\n",
    "shutil.rmtree(temp_folder, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bf4b67",
   "metadata": {},
   "source": [
    "# Augmentation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3ed690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import copy\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c96fea8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting ../data/pomelo-detection/train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting images: 100%|██████████| 173/173 [00:25<00:00,  6.71image/s, augmented_bboxes=5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented ../data/pomelo-detection/train successfully.\n",
      "\tOriginal images: 173\n",
      "\tAugmented images: 1038\n",
      "Augmenting ../data/pomelo-detection/valid...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting images: 100%|██████████| 22/22 [00:03<00:00,  6.46image/s, augmented_bboxes=5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented ../data/pomelo-detection/valid successfully.\n",
      "\tOriginal images: 22\n",
      "\tAugmented images: 132\n",
      "Augmenting ../data/pomelo-detection/test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting images: 100%|██████████| 20/20 [00:03<00:00,  6.50image/s, augmented_bboxes=5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented ../data/pomelo-detection/test successfully.\n",
      "\tOriginal images: 20\n",
      "\tAugmented images: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Augment detection tasks\n",
    "classification_folder = os.path.join(DATA_FOLDER, \"pomelo-detection\")\n",
    "classification_temp_folder = os.path.join(classification_folder, \"temp\")\n",
    "target_folder = [os.path.join(classification_folder, target) for target in [\"train\", \"valid\", \"test\"]]\n",
    "\n",
    "for folder in target_folder:\n",
    "    print(f\"Augmenting {folder}...\")\n",
    "    if os.path.exists(classification_temp_folder):\n",
    "        shutil.rmtree(classification_temp_folder, ignore_errors=True)\n",
    "    os.makedirs(classification_temp_folder, exist_ok=True)\n",
    "\n",
    "    # Load annotations\n",
    "    with open(os.path.join(folder, \"_annotations.coco.json\"), \"r\") as f:\n",
    "        annotations = json.load(f)\n",
    "    new_annotations = copy.deepcopy(annotations)\n",
    "\n",
    "    max_image_id = max([image[\"id\"] for image in annotations[\"images\"]])\n",
    "    image_id_generator = itertools.count(max_image_id + 1)\n",
    "    \n",
    "    looper = tqdm(annotations[\"images\"], desc=\"Augmenting images\", unit=\"image\")\n",
    "    for image_data in looper:\n",
    "        # Get file path\n",
    "        file_path = os.path.join(folder, image_data[\"file_name\"])\n",
    "\n",
    "        # Get annotations\n",
    "        image_annotations = [annotation for annotation in annotations[\"annotations\"] if annotation[\"image_id\"] == image_data[\"id\"]]\n",
    "        bboxes, category_ids = [], []\n",
    "        for annotation in image_annotations:\n",
    "            # Get bounding box coordinates\n",
    "            x, y, w, h = annotation[\"bbox\"]\n",
    "            bboxes.append([x, y, w, h])\n",
    "            category_ids.append(annotation[\"category_id\"])\n",
    "        looper.set_postfix({\"bboxes\": len(bboxes)})\n",
    "\n",
    "        # Read image\n",
    "        image = cv2.imread(file_path)\n",
    "\n",
    "        for _ in range(AUGMENTATION_AMOUNT):\n",
    "            looper.set_postfix({\"augmented_bboxes\": _ + 1})\n",
    "            # Apply augmentations\n",
    "            augmented = DETECTION_AUGS(image=image, bboxes=bboxes, category_ids=category_ids)\n",
    "            augmented_image = augmented[\"image\"]\n",
    "            augmented_bboxes = augmented[\"bboxes\"]\n",
    "            augmented_category_ids = augmented[\"category_ids\"]\n",
    "\n",
    "            # Add augmented image\n",
    "            new_image_id = next(image_id_generator)\n",
    "            new_image_name = f\"{new_image_id}.jpg\"\n",
    "            new_image_path = os.path.join(classification_temp_folder, new_image_name)\n",
    "            cv2.imwrite(new_image_path, augmented_image)\n",
    "\n",
    "            # Add augmented annotations\n",
    "            for bbox, category_id in zip(augmented_bboxes, augmented_category_ids):\n",
    "                new_annotation = {\n",
    "                    \"id\": new_image_id,\n",
    "                    \"image_id\": new_image_id,\n",
    "                    \"category_id\": int(category_id),\n",
    "                    \"bbox\": bbox,\n",
    "                    \"area\": bbox[2] * bbox[3],\n",
    "                    \"senmentation\": [],\n",
    "                    \"iscrowd\": 0,\n",
    "                }\n",
    "                new_annotations[\"annotations\"].append(new_annotation)\n",
    "\n",
    "            # Add image to annotations\n",
    "            new_image = {\n",
    "                'id': new_image_id,\n",
    "                'license': image_data[\"license\"],\n",
    "                'file_name': new_image_name,\n",
    "                'height': image.shape[0],\n",
    "                'width': image.shape[1],\n",
    "                'date_captured': image_data[\"date_captured\"],\n",
    "                'extra': {\n",
    "                    'name': new_image_name\n",
    "                }\n",
    "            }\n",
    "            new_annotations[\"images\"].append(new_image)\n",
    "\n",
    "        # Move original image to temp folder\n",
    "        shutil.move(file_path, os.path.join(classification_temp_folder, image_data[\"file_name\"]))\n",
    "\n",
    "    # Save new annotations\n",
    "    with open(os.path.join(classification_temp_folder, \"_annotations.coco.json\"), \"w\") as f:\n",
    "        json.dump(new_annotations, f)\n",
    "\n",
    "    # Remove original folder \n",
    "    shutil.rmtree(folder, ignore_errors=True)\n",
    "\n",
    "    # Move temp folder to original folder\n",
    "    shutil.move(classification_temp_folder, folder)\n",
    "\n",
    "    print(f\"Augmented {folder} successfully.\")\n",
    "    print(f\"\\tOriginal images: {len(annotations['images'])}\")\n",
    "    print(f\"\\tAugmented images: {len(new_annotations['images'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1351bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting ../data/pomelo-classification/train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting images: 100%|██████████| 201/201 [02:04<00:00,  1.61image/s, filename=IMG_4911_jpg.rf.7a8a1758cd35672b0ee72e5f29ccf52c.jpg]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented ../data/pomelo-classification/train successfully.\n",
      "\tOriginal images: 216\n",
      "\tTotal images: 1206\n",
      "Augmenting ../data/pomelo-classification/valid...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting images: 100%|██████████| 5/5 [00:04<00:00,  1.10image/s, filename=IMG_4910_jpg.rf.0558eda1565b52e73879550aba2bc38a.jpg]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented ../data/pomelo-classification/valid successfully.\n",
      "\tOriginal images: 9\n",
      "\tTotal images: 30\n",
      "Augmenting ../data/pomelo-classification/test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting images: 100%|██████████| 8/8 [00:07<00:00,  1.01image/s, filename=IMG_4862_jpg.rf.f18b1ee1137dcf2eb72a74f74268b769.jpg]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented ../data/pomelo-classification/test successfully.\n",
      "\tOriginal images: 9\n",
      "\tTotal images: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Augment classification tasks\n",
    "classification_folder = os.path.join(DATA_FOLDER, \"pomelo-classification\")\n",
    "target_folder = [os.path.join(classification_folder, target) for target in [\"train\", \"valid\", \"test\"]]\n",
    "\n",
    "for folder in target_folder:\n",
    "    print(f\"Augmenting {folder}...\")\n",
    "\n",
    "    # Load annotations\n",
    "    class_annotations = pd.read_csv(os.path.join(folder, \"_classes.csv\"))\n",
    "    original_size = len(class_annotations)\n",
    "    if 'TestSet' in class_annotations.columns:\n",
    "        class_annotations = class_annotations[class_annotations['TestSet'] == 0]\n",
    "        class_annotations = class_annotations.drop(columns='TestSet')\n",
    "\n",
    "    looper = tqdm(class_annotations['filename'].tolist(), desc=\"Augmenting images\", unit=\"image\")\n",
    "    for filename in looper:\n",
    "        looper.set_postfix({\"filename\": filename})\n",
    "        # Get file path\n",
    "        file_path = os.path.join(folder, filename)\n",
    "\n",
    "        # Read image\n",
    "        image = cv2.imread(file_path)\n",
    "\n",
    "        new_rows = []\n",
    "        for _ in range(AUGMENTATION_AMOUNT):\n",
    "            # Apply augmentations\n",
    "            augmented = CLASSIFICATION_AUGS(image=image)\n",
    "            augmented_image = augmented[\"image\"]\n",
    "\n",
    "            # Save augmented image\n",
    "            new_image_name = os.path.basename(file_path) + f\"_{_}.jpg\"\n",
    "            new_image_path = os.path.join(folder, new_image_name)\n",
    "\n",
    "            cv2.imwrite(new_image_path, augmented_image)\n",
    "\n",
    "            # Add augmented image to annotations\n",
    "            new_row = class_annotations[class_annotations['filename'] == filename].iloc[0]\n",
    "            new_row[\"filename\"] = new_image_name\n",
    "            new_rows.append(new_row)\n",
    "\n",
    "        class_annotations = pd.concat([class_annotations, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "\n",
    "    # Save new annotations\n",
    "    class_annotations.to_csv(os.path.join(folder, \"_classes.csv\"), index=False)\n",
    "    print(f\"Augmented {folder} successfully.\")\n",
    "    print(f\"\\tOriginal images: {original_size}\")\n",
    "    print(f\"\\tTotal images: {len(class_annotations)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
